"""
This workflow calls variants multiple different callers (samtools, octopus, cortex) and adjudicates (=regenotype calls from different callers) using gramtools.
"""

from pathlib import Path

WORKFLOW = "call_variants"
DL_WORKFLOW = "download_data"


configfile: "analysis/configs/common.yaml"
configfile: f"analysis/configs/{DL_WORKFLOW}.yaml"


include: f"../common_utils.py"


container: config["container_gramtools"]

ds_to_ref = {
    "pf6": "Pfalciparum",
    "pf6_analysis_set": "Pfalciparum",
    "pvgv": "PvivaxP01",
    "pacb_ilmn_pf": "Pfalciparum",
}

GENE_BED = f'{config["gene_bed_dir"]}/pf6_26_genes.bed'

GMTOOLS_COMMIT = cu_get_gmtools_commit(config["container_gramtools"])
output_base = Path(f'{config["output_dir"]}/{WORKFLOW}')
output_gramtools = output_base / f"gram_adju_{GMTOOLS_COMMIT}"
output_samtools = output_base / "samtools"
output_octopus = output_base / "octopus"
output_cortex = output_base / "cortex"
output_gapfiller = output_base / "gapfiller"
output_ref_genomes = output_base / "ref_genomes"
output_mapped_reads_original = output_base / "mapped_reads" / "original_ref"
output_mapped_reads_induced = output_base / "mapped_reads" / "induced_ref"
cu_mk_output_dirs(dir())

pacb_ilmn_records = cu_load_pacb_ilmn_pf(config["pacb_ilmn_pf_tsv"])
pf6_records = cu_load_pf6(config["pf6_tsv"],use_analysis_set=True)
pvgv_records = cu_load_pvgv(config["pvgv_tsv"])
all_records = pacb_ilmn_records + pf6_records
#all_records = [rec for rec in pf6_records if rec.sample_name == "PE0089-C"]
#all_records = [rec for rec in pacb_ilmn_records if rec.sample_name == "PfGA01"]


rule all:
    input:
        gapfiller_vcfs=expand(
            f"{output_gapfiller}/{{record.dataset_name}}/{{record.sample_name}}/gapfiller_rebased.vcf.gz",
            record=all_records,
        ),


rule cv_index_ref_genome:
    input:
        input_genome=(
            f'{config["dl_output_dir"]}/ref_genomes/{{genome}}.genome.fasta.gz'
        ),
    output:
        idx_dir=directory(f"{output_ref_genomes}/{{genome}}"),
        idx_prefix=f"{output_ref_genomes}/{{genome}}/ref",
        finished_idx_file=f"{output_ref_genomes}/{{genome}}/ref.bwt",
    resources:
        mem_mb=4000,
    shell:
        """
        mkdir -p {output.idx_dir}
        gzip -dc {input} > {output.idx_prefix}
        bwa index {output.idx_prefix}
        """

rule cv_bwa_map_reads:
    input:
        idx_prefix=(
            lambda wildcards: f"{output_ref_genomes}/{ds_to_ref[wildcards.dataset_name]}/ref"
        ),
        finished_idx_file=(
            lambda wildcards: f"{output_ref_genomes}/{ds_to_ref[wildcards.dataset_name]}/ref.bwt"
        ),
        reads=cu_get_reads,
    output:
        f"{output_mapped_reads_original}/{{dataset_name}}/{{sample_name}}/mapped.bam"
    threads: 4
    shadow:
        "shallow"
    resources:
        mem_mb=4000,
    shell:
        """
        bwa mem -t {threads} -R "@RG\\tID:1\\tSM:{wildcards.sample_name}" {input.idx_prefix} {input.reads} > mapped.sam
        samtools sort -o {output} -O BAM mapped.sam
        samtools index {output}
        """


rule cv_run_samtools:
    input:
        idx_prefix=(
            lambda wildcards: f"{output_ref_genomes}/{ds_to_ref[wildcards.dataset_name]}/ref"
        ),
        mapped_reads=f"{output_mapped_reads_original}/{{dataset_name}}/{{sample_name}}/mapped.bam"
    output:
        f"{output_samtools}/{{dataset_name}}/{{sample_name}}/samtools.vcf.gz",
    threads: 4
    shadow:
        "shallow"
    resources:
        mem_mb=4000,
    shell:
        """
        mkdir -p $(dirname {output})
        bcftools mpileup -f {input.idx_prefix} {input.mapped_reads} | bcftools call -O z -o {output} -vm --ploidy 1
        """

rule cv_run_octopus:
    input:
        ref_genome=cu_get_ref_genome,
        mapped_reads=f"{output_mapped_reads_original}/{{dataset_name}}/{{sample_name}}/mapped.bam"
    output:
        vcf_pre_filtered=f"{output_octopus}/{{dataset_name}}/{{sample_name}}/octopus_pre_overlap_removed.vcf.gz",
        vcf=f"{output_octopus}/{{dataset_name}}/{{sample_name}}/octopus.vcf.gz",
    params:
        vcf_overlap_remover=f'{config["common_scripts"]}/remove_vcf_overlaps.py',
    threads: 4
    shadow:
        "shallow"
    resources:
        mem_mb=8000,
    shell:
        """
        mkdir -p $(dirname {output})
        gzip -dc {input.ref_genome} > ref_genome.fa
        samtools faidx ref_genome.fa
        octopus -R ref_genome.fa -I {input.mapped_reads} --threads {threads} --organism-ploidy 1 -o {output.vcf_pre_filtered}
        python3 {params.vcf_overlap_remover} {output.vcf_pre_filtered} {output.vcf}
        """

rule cv_run_cortex:
    input:
        ref_genome=cu_get_ref_genome,
        reads=cu_get_reads,
    output:
        f"{output_cortex}/{{dataset_name}}/{{sample_name}}/cortex.vcf.gz",
    resources:
        mem_mb=12000,
    shadow:
        "shallow"
    params:
        cortex_script=f'{config["scripts"]}/{WORKFLOW}/run_cortex.py',
    shell:
        """
        gzip -dc {input.ref_genome} > ref.fa # Cortex cannot run on gzipped reference
        python3 {params.cortex_script} ref.fa '{input.reads}' out.vcf {wildcards.sample_name}
        bgzip out.vcf
        bcftools view -f PASS out.vcf.gz | bcftools norm -c x --rm-dup all -f {input.ref_genome} -Oz > {output}
        """


rule cv_gramtools_adjudicate:
    input:
        ref_genome=cu_get_ref_genome,
        octopus_vcf=(
            f"{output_octopus}/{{dataset_name}}/{{sample_name}}/octopus.vcf.gz"
        ),
        cortex_vcf=f"{output_cortex}/{{dataset_name}}/{{sample_name}}/cortex.vcf.gz",
        reads=cu_get_reads,
    output:
        vcf=f"{output_gramtools}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        build_rep=(
            f"{output_gramtools}/{{dataset_name}}/{{sample_name}}/build_report.json"
        ),
        geno_rep=(
            f"{output_gramtools}/{{dataset_name}}/{{sample_name}}/genotype_report.json"
        ),
    shadow:
        "shallow"
    threads: 10
    resources:
        mem_mb=8000,
    shell:
        """
        filter="PASS,."
        bcftools view -f "$filter" {input.octopus_vcf} -Ov | awk '$4 $5 !~ /N/ {{print $0}}' > vcf1.vcf
        bgzip vcf1.vcf
        bcftools view -f "$filter" {input.cortex_vcf} -Oz -o vcf2.vcf.gz
        gramtools build --ref {input.ref_genome} --vcf vcf1.vcf.gz --vcf vcf2.vcf.gz --kmer_size 12 -o gram
        gramtools genotype --max_threads {threads} -i gram -o genotype --reads {input.reads} --sample_id {wildcards.sample_name}
        mv genotype/genotype/*.vcf.gz {output.vcf}
        mv gram/build_report.json {output.build_rep}
        mv genotype/genotype_report.json {output.geno_rep}
        """

rule cv_map_to_induced_ref:
    input:
        ref_genome=lambda wildcards: f'{config["dl_output_dir"]}/ref_genomes/' + ds_to_ref[wildcards.dataset_name] + ".genome.fasta.gz",
        vcf=f"{output_gramtools}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        reads=cu_get_reads,
    output:
        induced_bam = f"{output_mapped_reads_induced}/{{dataset_name}}/{{sample_name}}/mapped.bam",
        induced_ref = f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
    shadow:
        "shallow"
    threads: 4
    resources:
        mem_mb=4000,
    shell:
        """
        mkdir -p $(dirname {output.induced_ref})
        cp {input.vcf} adju.vcf.gz
        bcftools index adju.vcf.gz
        bgzip -dc {input.ref_genome} | bcftools consensus -s {wildcards.sample_name} adju.vcf.gz > induced_ref.fa
        bwa index induced_ref.fa
        bwa mem -t {threads} -R "@RG\\tID:1\\tSM:{wildcards.sample_name}" induced_ref.fa {input.reads} > mapped.sam
        samtools sort -o {output.induced_bam} -O BAM mapped.sam
        samtools index {output.induced_bam}
        bgzip -c induced_ref.fa > {output.induced_ref}
        samtools faidx {output.induced_ref}
        """

rule cv_translate_bed_for_gapfiller:
    input:
        translation_ref=lambda wildcards: f'{config["dl_output_dir"]}/ref_genomes/' + ds_to_ref[wildcards.dataset_name] + ".genome.fasta.gz",
        translation_vcf=f"{output_gramtools}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        translation_bed = GENE_BED,
    output:
        translated_bed = f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/induced_features.bed",
    params:
        script_bed_translate=f'{config["scripts"]}/common_utils/shift_to_induced_genome_coords.py',
    shell:
        """
        python3 {params.script_bed_translate} {input.translation_bed} {input.translation_ref} {input.translation_vcf} {output.translated_bed}
        """

rule cv_run_gapfiller:
    input:
        induced_bam = rules.cv_map_to_induced_ref.output.induced_bam,
        induced_ref = rules.cv_map_to_induced_ref.output.induced_ref,
        pre_induced_ref=lambda wildcards: f'{config["dl_output_dir"]}/ref_genomes/' + ds_to_ref[wildcards.dataset_name] + ".genome.fasta.gz",
        pre_induced_vcf=f"{output_gramtools}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        bed_regions_to_call_in = f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/induced_features.bed"
    output:
        gapfiller_vcf = f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/gapfiller.vcf.gz",
        gapfiller_vcf_rebased = f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/gapfiller_rebased.vcf.gz",
        mapped_contig_bam = f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/mapped_contigs.bam", 
    shadow:
        "shallow"
    resources:
        mem_mb=4000,
    params:
        script_rebase=f'{config["scripts"]}/{WORKFLOW}/rebase_calls.py',
        INSERT_SIZE_MEAN = config["gapfiller_insert_size_mean"],
        INSERT_SIZE_STDV = config["gapfiller_insert_size_stdv"]
    shell:
        """
        samtools view -G 2 {input.induced_bam} > not_properly_aligned.sam
        IFS="\n"; for gene_line in $(cat {input.bed_regions_to_call_in})
        do
            IFS="\t"; elems=($gene_line)
            adjusted_start=$((${{elems[1]}} + 1))
            reg="${{elems[0]}}:${{adjusted_start}}-${{elems[2]}}"
            gene_name=${{elems[3]}}
            samtools view -h {input.induced_bam} $reg | samtools sort -n > gene_reads.bam
            cat <(samtools view -h {input.induced_bam} $reg) not_properly_aligned.sam | samtools sort > query_reads.bam
            GapFiller --query-sam query_reads.bam --seed-sam gene_reads.bam --seed-ins {params.INSERT_SIZE_MEAN} --seed-var {params.INSERT_SIZE_STDV} --output-prefix gene_contigs
            seqkit replace -p "contig" -r "${{gene_name}}_contig" gene_contigs.fasta >> all_gene_contigs.fasta
        done
        minimap2 -a -c --cs -R "@RG\\tID:1\\tSM:{wildcards.sample_name}" {input.induced_ref} all_gene_contigs.fasta | samtools sort > {output.mapped_contig_bam}
        samtools index {output.mapped_contig_bam}
        bgzip -dc {input.induced_ref} > induced_ref.fa
        samtools faidx induced_ref.fa
        octopus -I {output.mapped_contig_bam} -R induced_ref.fa --organism-ploidy 1 --assemble-all -o gapfiller.vcf
        bgzip gapfiller.vcf && bcftools index gapfiller.vcf.gz 
        bcftools filter -o {output.gapfiller_vcf} -Oz -R {input.bed_regions_to_call_in} -i 'FORMAT/DP > 2 & FILTER="PASS"' gapfiller.vcf.gz
        python3 {params.script_rebase} {output.gapfiller_vcf} {input.induced_ref} {input.pre_induced_vcf} gapfiller_rebased.vcf 
        bgzip -c gapfiller_rebased.vcf > {output.gapfiller_vcf_rebased}
        # Check the rebased variants are consistent with the original reference; errors (return code != 0) if not
        bcftools index {output.gapfiller_vcf_rebased}
        bcftools consensus -f {input.pre_induced_ref} {output.gapfiller_vcf_rebased} > /dev/null
        """
    
