"""
This workflow prepares the data needed for the rest of the analysis:

* Downloads reads from ENA for pf6, pvgv and pacb_ilmn_pf. Multiple ENA samples/runs are concatenated.
  The reads are subsampled to a maximum genome coverage and also trimmed.

* Downloads the PACB assemblies for pacb_ilmn_pf.

* Downloads the falciparum and vivax reference genomes (and gffs).

"""

from pathlib import Path

WORKFLOW = "download_data"


configfile: "analysis/configs/common.yaml"
configfile: f"analysis/configs/{WORKFLOW}.yaml"


include: "../common_utils.py"
include: f"../{WORKFLOW}/utils.py"


output_base = Path(f'{config["output_dir"]}/{WORKFLOW}')
output_gene_beds = Path(f"{output_base}/gene_beds")
output_ref_genomes = Path(f"{output_base}/ref_genomes")
output_pacb_pf_assemblies = Path(f"{output_base}/pacb_ilmn_pf/assemblies")
output_vcfs = Path(f"{output_base}/vcfs")
cu_mk_output_dirs(dir())

ena_records = (
    cu_load_pf6(config["pf6_tsv"])
    + cu_load_pvgv(config["pvgv_tsv"])
    + cu_load_pacb_ilmn_pf(config["pacb_ilmn_pf_tsv"])
    + cu_load_clone_trees(config["clone_tree_tsv"])
)


sample_to_ena_IDs = {record.sample_name: record.ena_IDs for record in ena_records}
pacb_pf_fnames = [
    f"{record.sample_name}.April2018.fasta.gz"
    for record in cu_load_pacb_ilmn_pf(config["pacb_ilmn_pf_tsv"])
]

pf_chrom_list = list(map(lambda v: f"0{v}", range(1, 10))) + list(
    map(str, range(10, 15))
)


rule all:
    input:
        ena_reads=expand(
            f"{output_base}/{{record.dataset_name}}/{{record.sample_name}}/reads_{{i}}.final.fastq.gz",
            record=ena_records,
            i=[1, 2],
        ),
        pacb_pf_assemblies=expand(
            f"{output_pacb_pf_assemblies}/{{assembly_fname}}",
            assembly_fname=pacb_pf_fnames,
        ),
        ref_genomes=expand(
            f"{output_ref_genomes}/{{genome}}{{extension}}",
            genome=config["ref_genomes"]["genomes"],
            extension=config["ref_genomes"]["extensions"],
        ),
        gene_beds=expand(
            f"{output_gene_beds}/{{gene_list_name}}.bed",
            gene_list_name=config["pf6_gene_list_files"]
            + config["pvivax_gene_list_files"],
        ),
        vcfs=expand(
            f"{output_vcfs}/{{dataset}}/combined_{{gene_list_name}}_filterPASS.vcf.gz",
            gene_list_name=config["pf6_gene_list_files"],
            dataset=["pf6", "pf7"],
        ),


rule dd_ena:
    output:
        expand(
            "{output_base}/{{dataset_name}}/{{sample_name}}/reads_{i}.fastq.gz",
            output_base=output_base,
            i=[1, 2],
        ),
    params:
        script=f'{config["scripts"]}/{WORKFLOW}/dl_ena.py',
        ena_IDs=lambda wildcards: sample_to_ena_IDs[wildcards.sample_name],
    shell:
        f"python3 {{params.script}} {{params.ena_IDs}} {output_base}/{{wildcards.dataset_name}}/{{wildcards.sample_name}}"


rule dd_subsample_reads:
    input:
        ir1=f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_1.fastq.gz",
        ir2=f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_2.fastq.gz",
    output:
        or1=temp(
            f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_1.subsampled.fastq.gz"
        ),
        or2=temp(
            f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_2.subsampled.fastq.gz"
        ),
    params:
        genome_size=lambda wildcards: cu_get_genome_size(wildcards.dataset_name),
        max_coverage=config["subsampling_maxcov"],
    container:
        config["container_gramtools"]
    resources:
        mem_mb=4000,
    shell:
        "rasusa -i {input.ir1} -i {input.ir2} --coverage {params.max_coverage} --genome-size {params.genome_size} -o {output.or1} -o {output.or2}"


rule dd_trim_reads:
    input:
        ir1=f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_1.subsampled.fastq.gz",
        ir2=f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_2.subsampled.fastq.gz",
    output:
        or1=f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_1.final.fastq.gz",
        or2=f"{output_base}/{{dataset_name}}/{{sample_name}}/reads_2.final.fastq.gz",
    threads: 4
    container:
        config["container_gramtools"]
    resources:
        mem_mb=15000,
    shell:
        "java -jar /software/Trimmomatic-0.36/trimmomatic-0.36.jar PE -threads {threads} -phred33 {input.ir1} {input.ir2} {output.or1} /dev/null {output.or2} /dev/null ILLUMINACLIP:/software/Trimmomatic-0.36/adapters/TruSeq3-PE-2.fa:2:30:10 LEADING:10 TRAILING:10 SLIDINGWINDOW:4:15 MINLEN:50"


rule dd_pacb_pf_assemblies:
    output:
        rules.all.input.pacb_pf_assemblies,
    shell:
        f"wget {config['pacb_pf_ftp']} -nc -P {output_pacb_pf_assemblies}"


rule dd_ref_genomes:
    wildcard_constraints:
        extension="\.(genome.fasta.gz|gff3.gz)",
    output:
        f"{output_ref_genomes}/{{genome}}{{extension}}",
    shell:
        f"wget {config['ref_genomes']['ftp_root']}/{{wildcards.genome}}{{wildcards.extension}} -P {output_ref_genomes}"


rule dd_index_ref_genomes:
    input:
        f"{output_ref_genomes}/{{genome}}.fasta.gz",
    output:
        f"{output_ref_genomes}/{{genome}}.fasta.gz.fai",
    container:
        config["container_gramtools"]
    shell:
        """
        input={input}
        to_gzip="${{input/.gz/}}"
        # The vivax genome has n's, and gramtools does not deal with n's yet
        fastaq replace_bases {input} "$to_gzip" n c
        bgzip --force "$to_gzip"
        samtools faidx {input}
        """


rule dd_make_gene_bed:
    input:
        gene_list_file=f'{config["gene_list_dir"]}/{{gene_list_name}}.txt',
        genome_gff=(
            lambda wildcards: f"{output_ref_genomes}/{cu_gene_list_to_genome(wildcards)}.gff3.gz"
        ),
    output:
        gene_bed=f"{output_gene_beds}/{{gene_list_name}}.bed",
    container:
        config["container_gramtools"]
    params:
        gff_to_bed_script=f'{config["scripts"]}/{WORKFLOW}/gff_to_bed.sh',
    shell:
        "bash {params.gff_to_bed_script} {input.gene_list_file} {input.genome_gff} {output}"


rule dd_get_vcf:
    wildcard_constraints:
        chrom="[0-9]+",
    output:
        vcf=f"{output_vcfs}/{{dataset_name}}/{{chrom}}.vcf.gz",
    params:
        vcf_url=get_vcf_url,
    shell:
        """
        mkdir -p $(dirname {output.vcf})
        if [[ ! -e {output.vcf} ]]; then
            wget {params.vcf_url} -nc -O {output.vcf}
        fi
        wget {params.vcf_url}.md5 -O {output.vcf}.md5
        # Check downloaded file integrity
        diff <(cut -f 1 -d ' ' {output.vcf}.md5) <(md5sum {output.vcf} | cut -f 1 -d ' ')
        """


rule dd_concat_vcfs:
    input:
        vcfs=expand(
            f"{output_vcfs}/{{dataset_name}}/{{chrom}}.vcf.gz",
            chrom=pf_chrom_list,
            allow_missing=True,
        ),
    output:
        vcf=f"{output_vcfs}/{{dataset_name}}/combined.vcf.gz",
    shell:
        """
        bcftools concat -Oz {input.vcfs} > {output.vcf}
        bcftools index {output.vcf}
        """


def get_vcf_to_subset(wildcards):
    if wildcards.dataset == "pf6":
        return f"{output_vcfs}/{wildcards.dataset}/combined.vcf.gz"
    elif wildcards.dataset == "pf7":
        return config["pf7_vcf"]


rule dd_subset_vcfs:
    input:
        vcf=get_vcf_to_subset,
        gene_bed=f"{output_gene_beds}/{{gene_list_name}}.bed",
    output:
        vcf_nofilter=f"{output_vcfs}/{{dataset}}/combined_{{gene_list_name}}.vcf.gz",
        vcf_filterPASS=(
            f"{output_vcfs}/{{dataset}}/combined_{{gene_list_name}}_filterPASS.vcf.gz"
        ),
    shell:
        """
        mkdir -p $(dirname {output})
        regions=$(awk 'ORS=","{{start=$2 + 1;print $1":"start"-"$3}}' {input.gene_bed})
        bcftools view -r "$regions" {input.vcf} -Oz > {output.vcf_nofilter}
        bcftools view -f "PASS,." {output.vcf_nofilter} -Oz > {output.vcf_filterPASS}
        bcftools index {output.vcf_filterPASS}
        """
