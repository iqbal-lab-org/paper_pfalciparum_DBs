"""
Workflow to genotype the clone tree samples
Steps:
    * Run gramtools genotyping on the pf6 graph
    * Run my variant calling pipeline on top of that: octopus/cortex, adjudicate, gapfiller
Re-uses the rules in other workflows, imported as modules, to do so
"""
WORKFLOW = "generational_samples"


configfile: "analysis/configs/common.yaml"


include: "../common_utils.py"


GMTOOLS_COMMIT = cu_get_gmtools_commit(config["container_gramtools"])
# Input: gramtools pf6 graph
GRAM_JOINT_GENO_PARAMS = "pf6__analysis_set_fws95__gapfiller__pf6_26_genes_mml7_k13"
input_gram_build = (
    f"/hps/nobackup/iqbal/bletcher/plasmo_surfants/analysis/outputs/joint_genotyping/gram_build_{GMTOOLS_COMMIT}/"
    + "/".join(GRAM_JOINT_GENO_PARAMS.split("__"))
    + "/kmers_stats"
)

output_base = Path(f'{config["output_dir"]}/{WORKFLOW}')
gram_joint_geno_path = f"gram_jointgeno_{GMTOOLS_COMMIT}__{GRAM_JOINT_GENO_PARAMS}"
output_gram_joint_geno = output_base / gram_joint_geno_path
output_octopus = output_base / "octopus"
output_cortex = output_base / "cortex"
output_gram_adju = output_base / f"gram_adju_{GMTOOLS_COMMIT}"
output_gapfiller = output_base / "gapfiller"
output_ir_stats = output_base / "ir_stats"
output_ir_stats_per_sample = output_ir_stats / "per_sample"
output_gene_seqs = output_base / "induced_gene_seqs"
cu_mk_output_dirs(dir())

GENE_LIST_NAME = "pf6_26_genes"
GENE_BED = f'{config["gene_bed_dir"]}/{GENE_LIST_NAME}.bed'
GENE_BED_FOR_EVAL = config["eval_bed_files"][GENE_LIST_NAME]
GENES_TO_INDUCE = cu_load_bed(GENE_LIST_NAME)
ALL_TOOLS = [gram_joint_geno_path,"cortex","octopus",f"gram_adju_{GMTOOLS_COMMIT}","gapfiller"]


# This has to appear after output_ definitions and common_utils.py inclusion
include: "utils.py"


clone_tree_samples = [
    elem.sample_name for elem in cu_load_clone_trees(config["clone_tree_tsv"])
    ]

crosses_samples = [
    elem.sample_name for elem in cu_load_crosses(config["crosses_tsv"])
    ]

DATASET_NAMES = ["clone_trees","crosses"]

#### Modules ###
config["min_match_len"] = None
config["kmer_size"] = None


module joint_geno:
    snakefile:
        "../joint_genotyping/Snakefile"
    config:
        config


module call_variants:
    snakefile:
        "../call_variants/Snakefile"
    config:
        config


wildcard_constraints:
    sample_name="[^/]+",
    tool="[^/]+",


rule all:
    input:
        eval_stats=expand(
                f"{output_ir_stats}/{{dataset_name}}_ir_stats.tsv",
                dataset_name=DATASET_NAMES
                ),
        translated_beds=expand(
                f"{output_base}/{{tool}}/clone_trees/{{sample_name}}/{GENE_LIST_NAME}_induced.bed",
                tool=ALL_TOOLS,
                sample_name=clone_tree_samples
                ) + expand(
                f"{output_base}/{{tool}}/crosses/{{sample_name}}/{GENE_LIST_NAME}_induced.bed",
                tool=ALL_TOOLS,
                sample_name=crosses_samples
                ),
        # below will fail to run if above has not been already produced.
        #gene_seqs=expand(
        #        f"{output_gene_seqs}/{{dataset_name}}/{{tool}}/{{gene}}.fa",
        #        dataset_name = DATASET_NAMES,
        #        tool = ALL_TOOLS,
        #        gene = GENES_TO_INDUCE
        #        )


use rule jg_gramtools_genotype from joint_geno with:
    input:
        gram_build=input_gram_build,
        reads=cu_get_reads,
    output:
        vcf=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        jvcf=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/final.json",
    params:
        geno_dir=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/genotyped",


# This rule can produce induced references for multiple different tools
use rule cv_map_to_induced_ref from call_variants with:
    input:
        ref_genome=gs_get_ref_genome,
        vcf=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        reads=cu_get_reads,
    output:
        induced_ref=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
        induced_bam=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/induced_ref_mapped.bam",
    params:
        script_induce_seqs=f'{config["common_scripts"]}/induce_gene_seqs.sh',


rule gs_translate_bed:
    input:
        translation_ref=gs_get_ref_genome,
        translation_vcf=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        translation_bed=gs_get_translation_bed,
        translation_bed_for_eval=gs_get_translation_bed_for_eval,
    output:
        translated_bed=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/{GENE_LIST_NAME}_induced.bed",
        translated_bed_for_eval=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/{GENE_LIST_NAME}_for_eval_induced.bed",
    params:
        script_bed_translate=f'{config["scripts"]}/common_utils/shift_to_induced_genome_coords.py',
    shell:
        """
        python3 {params.script_bed_translate} {input.translation_bed} {input.translation_ref} {input.translation_vcf} {output.translated_bed}
        python3 {params.script_bed_translate} {input.translation_bed_for_eval} {input.translation_ref} {input.translation_vcf} {output.translated_bed_for_eval}
        """


use rule cv_run_octopus from call_variants with:
    input:
        ref_genome=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
        mapped_reads=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/induced_ref_mapped.bam",
    output:
        vcf_pre_filtered=f"{output_octopus}/{{dataset_name}}/{{sample_name}}/pre_overlap_removed.vcf.gz",
        vcf=f"{output_octopus}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",


use rule cv_run_cortex from call_variants with:
    input:
        ref_genome=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
        reads=cu_get_reads,
    output:
        vcf=f"{output_cortex}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",


use rule cv_gramtools_adjudicate from call_variants with:
    input:
        ref_genome=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
        octopus_vcf=f"{output_octopus}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        cortex_vcf=f"{output_cortex}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        reads=cu_get_reads,
    output:
        vcf=f"{output_gram_adju}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        build_rep=f"{output_gram_adju}/{{dataset_name}}/{{sample_name}}/build_report.json",
        geno_rep=f"{output_gram_adju}/{{dataset_name}}/{{sample_name}}/genotype_report.json",


use rule cv_run_gapfiller from call_variants with:
    input:
        induced_bam=f"{output_gram_adju}/{{dataset_name}}/{{sample_name}}/induced_ref_mapped.bam",
        induced_ref=f"{output_gram_adju}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
        pre_induced_ref=f"{output_gram_joint_geno}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
        pre_induced_vcf=f"{output_gram_adju}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        bed_regions_to_call_in=f"{output_gram_adju}/{{dataset_name}}/{{sample_name}}/{GENE_LIST_NAME}_induced.bed",
    output:
        gapfiller_vcf=f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        gapfiller_vcf_rebased=f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/final_rebased.vcf.gz",
        mapped_contig_bam=f"{output_gapfiller}/{{dataset_name}}/{{sample_name}}/mapped_contigs.bam",


rule gs_induced_ref_get_stats:
    """
    Similar rule as in eval_varcalls workflow, but simpler
    """
    input:
        bed_to_translate=gs_get_translation_bed_for_eval,
        ref_to_translate=gs_get_ref_genome,
        bed_for_insert_size=config["pf3d7_2018_11_core_regions"],
        induced_ref=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/induced_ref.fa.gz",
        vcf=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/final.vcf.gz",
        induced_bam=f"{output_base}/{{tool}}/{{dataset_name}}/{{sample_name}}/induced_ref_mapped.bam",
    output:
        f"{output_ir_stats_per_sample}/{{dataset_name}}/{{tool}}_{{sample_name}}.tsv",
    params:
        script_get_stats=f'{config["scripts"]}/eval_varcalls/get_induced_ref_stats.py',
    shell:
        """
        bcftools index -f {input.vcf}
        python3 {params.script_get_stats} {input.bed_to_translate} {input.ref_to_translate} {input.induced_ref} {input.vcf} {input.induced_bam} --out_fname {output} --sample_name {wildcards.sample_name} --tool_name {wildcards.tool} -bi {input.bed_for_insert_size}
        """

rule gs_get_all_ir_stats:
    input:
        gs_get_expected_ir_stats,
    output:
        f"{output_ir_stats}/{{dataset_name}}_ir_stats.tsv",
    params:
        script_get_stats=f'{config["scripts"]}/eval_varcalls/get_induced_ref_stats.py',
    shell:
        """
        python3 {params.script_get_stats} --header_only > {output}
        cat {output_ir_stats_per_sample}/{wildcards.dataset_name}/*.tsv >> {output}
        """


rule gs_get_induced_gene_seqs:
    """
    This rule has no specified inputs because snakemake too slow to compute them. Its required inputs are all created in process of making ir_stats.tsv; thus that has to have been made first.
    """
    output:
        expand(
                f"{output_gene_seqs}/{{tool}}/{{dataset_name}}/{{gene}}.fa",
                gene=GENES_TO_INDUCE,
                allow_missing=True
                )
    params:
        output_base=output_base,
        bed_name=f"{GENE_LIST_NAME}_induced.bed",
        samples=clone_tree_samples,
        genes=GENES_TO_INDUCE,
        output_tool_dir=f"{output_gene_seqs}/{{tool}}",

    shell:
        """
        mkdir -p {params.output_tool_dir}
        input_tool_dir={params.output_base}/{wildcards.tool}
        for output_file in {output}; do > "$output_file"; done
        for sample in {params.samples}; do
            bed_fname="${{input_tool_dir}}/${{sample}}/{params.bed_name}"
            ref_fname="${{input_tool_dir}}/${{sample}}/induced_ref.fa.gz"
            IFS="\n"; for gene_line in $(cat "$bed_fname")
            do
                IFS="\t"; elems=($gene_line)    
                adj_start=$((${{elems[1]}} + 1))
                reg="${{elems[0]}}:${{adj_start}}-${{elems[2]}}"
                gene_name=${{elems[3]}}
                new_name="${{gene_name}}_${{sample}}"
                samtools faidx "$ref_fname" $reg |
                    sed 's/>.*/>'"$new_name"'/' >> {params.output_tool_dir}/"${{gene_name}}.fa"
            done
        done
        """
