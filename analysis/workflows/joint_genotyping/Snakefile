import re

WORKFLOW = "joint_genotyping"


configfile: "analysis/configs/common.yaml"
configfile: f"analysis/configs/{WORKFLOW}.yaml"


include: f"../common_utils.py"
include: "utils.py"


GMTOOLS_COMMIT = cu_get_gmtools_commit(config["container_gramtools"])
output_base = Path(f'{config["output_dir"]}/{WORKFLOW}')
output_gram_build = output_base / f"gram_build_{GMTOOLS_COMMIT}"
output_gram_gtype = output_base / f"gram_jointgeno_{GMTOOLS_COMMIT}"
cu_mk_output_dirs(dir())
prg_dir = f'{config["output_dir"]}/make_prgs'


# These two arrays' elements are paired together
dataset_names = ["pf6", "pacb_ilmn_pf@pf6"]
datasubset_names = ["analysis_set_fws95"]
gene_list_names = ["pf6_26_genes"]

def get_fofn(wcards):
    result = f"{output_gram_gtype}/{wcards.dataset_name}/{wcards.datasubset_name}/{wcards.tool}/final_merged/{wcards.gene_list_name}_{wcards.min_match_len}_{wcards.kmer_size}_fofn_{{ext}}.txt"
    if wcards.ext == "json":
        return result.format(ext="json")
    elif wcards.ext == "vcf.gz":
        return result.format(ext="vcf")
    else:
        raise ValueError(f"Unknown extension {wcards.ext}")

def expand_inputs(wcards):
    """
    Produces the gramtools output vcfs based on a dataset name, paired with a gene list name.
    """
    sample_names = cu_get_sample_names_fws_matching(wcards.dataset_name + wcards.datasubset_name)
    result = f"{output_gram_gtype}/{wcards.dataset_name}/{wcards.datasubset_name}/{wcards.tool}/{wcards.gene_list_name}_{wcards.min_match_len}_{wcards.kmer_size}/{{sample_name}}/final.{{ext}}"
    ext = ""
    if wcards.ext == "json":
        ext = "json"
    elif wcards.ext == "vcf":
        ext = "vcf.gz"
    else:
        raise ValueError(f"Unknown extension {wcards.ext}")
    return expand(result, 
            sample_name=sample_names,
            ext = ext)


rule all:
    input:
        expand(
                f"{output_gram_gtype}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/final_merged/{{gene_list_name}}_{{min_match_len}}_{{kmer_size}}_merged.{{extension}}",
        dataset_name=dataset_names,
        datasubset_name=datasubset_names,
        tool=[f"gram_adju_{GMTOOLS_COMMIT}","gapfiller"],
        gene_list_name=gene_list_names,
        min_match_len=config["min_match_len"],
        kmer_size=config["kmer_size"],
        extension=["vcf.gz","json"]
        )



rule jg_gramtools_build:
    input:
        ref_genome=cu_get_ref_genome,
        prg=f"{prg_dir}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/mn5_mml{{min_match_len}}/{{gene_list_name}}_prg",
    output:
        f"{output_gram_build}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/{{gene_list_name}}_mml{{min_match_len}}_k{{kmer_size}}/kmers_stats",
    resources:
        mem_mb=20000,
    shell:
        """
        outdir=$(dirname {output})
        gramtools build --ref {input.ref_genome} --prg {input.prg} --kmer_size {wildcards.kmer_size} -o ${{outdir}} --force
        """


rule jg_gramtools_genotype:
    input:
        gram_build=jg_get_gram_build,
        reads=cu_get_reads,
    output:
        vcf=f"{output_gram_gtype}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/{{gene_list_name}}_{{min_match_len}}_{{kmer_size}}/{{sample_name}}/final.vcf.gz",
        jvcf=f"{output_gram_gtype}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/{{gene_list_name}}_{{min_match_len}}_{{kmer_size}}/{{sample_name}}/final.json",
    params:
        geno_dir=f"{output_gram_gtype}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/{{gene_list_name}}_{{min_match_len}}_{{kmer_size}}/{{sample_name}}/genotyped",
    threads: 10
    resources:
        mem_mb=5000,
    shell:
        """
        gram_build=$(dirname {input.gram_build})
        gramtools genotype -i ${{gram_build}} -o {params.geno_dir} --reads {input.reads} --sample_id {wildcards.sample_name} --max_threads {threads} --force
        cp {params.geno_dir}/genotype/*.vcf.gz {output.vcf}
        bcftools index {output.vcf}
        cp {params.geno_dir}/genotype/genotyped.json {output.jvcf}
        """

rule jg_make_fofn:
    input:
        vcfs=expand_inputs,
    output:
        fofn=f"{output_gram_gtype}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/final_merged/{{gene_list_name}}_{{min_match_len}}_{{kmer_size}}_fofn_{{ext}}.txt",
    run:
        with open(output.fofn,"w") as outfile:
            for vcf in input.vcfs:
                outfile.write(vcf+"\n")

rule jg_merge_files:
    input:
        get_fofn,
    output:
        f"{output_gram_gtype}/{{dataset_name}}/{{datasubset_name}}/{{tool}}/final_merged/{{gene_list_name}}_{{min_match_len}}_{{kmer_size}}_merged.{{ext}}"
    resources:
        mem_mb=10000,
    shell:
        """
        if [[ "{wildcards.ext}" == "json" ]];then
            combine_jvcfs {input} {output}
        else
            bcftools merge -l {input} -Oz -m both > {output}
        fi
        """
